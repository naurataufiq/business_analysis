% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Exploring Yelp Toronto Businesses and Their Reviews in Relation to Nearby Attractions},
  pdfauthor={Naura Izzah Taufiq (1009713669)},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Exploring Yelp Toronto Businesses and Their Reviews in Relation
to Nearby Attractions}
\author{Naura Izzah Taufiq (1009713669)}
\date{}

\begin{document}

\pagestyle{fancy}
\fancyhead[L]{Business Analysis}
\fancyhead[R]{Naura Taufiq}

\maketitle

\section{A. Introduction}\label{a.-introduction}

Tourism plays a major role in shaping the economy of Toronto, Canada's
largest city and a popular tourist destination. Understanding how
proximity to attractions influences business success can offer valuable
insights for business owners, urban planners, and tourism boards. In
this project, we explore the relationship between \textbf{Toronto Yelp
businesses}, their \textbf{reviews}, and their proximity to
\textbf{tourist attractions}, by interactive exploratory data analysis
and producing predictive modelling using machine learning models. This
study builds upon the initial exploratory and sentiment analysis of
Toronto businesses by developing predictive models to understand what
factors influence Yelp business ratings. After exploring how tourist
attractions affect nearby businesses and examining sentiment patterns
across reviews, we now aim to determine whether these factors can
predict business performance.

The analysis leverages three datasets: Toronto's Places of Interest and
Attractions from the Toronto Open Data portal, and Yelp Business and
Review datasets from Kaggle (sourced from the Yelp Open Dataset),
filtered to include only Toronto-based businesses and their reviews. By
leveraging initial sentiment analysis results and using machine learning
techniques, we explore whether a combination of review sentiment, user
engagement metrics, and proximity to tourist attractions can effectively
forecast how customers rate businesses. The models developed in this
analysis could provide valuable insights for business owners considering
location strategies, current businesses looking to improve their
ratings, and city planners interested in maximizing the tourism-business
relationship across Toronto.

\section{B. Methods}\label{b.-methods}

\subsection{B.1. Data Loading, Cleaning, Merging and Initial
Analysis}\label{b.1.-data-loading-cleaning-merging-and-initial-analysis}

An extensive data preprocessing and initial analysis (including
sentiment analysis) was done initially by mid-project, and the full
report can be viewed
\href{https://github.com/naurataufiq/business-analysis/blob/main/business_analysis.pdf}{here}.

To summarize the initial preprocessing, datasets were sourced from both
the Toronto Open Data API and the Yelp Open Data subsets from Kaggle.
The Toronto dataset, accessed via the CKAN interface, included
information on attractions such as names, categories, coordinates,
contact details, and descriptions. Yelp provided two key datasets: one
on businesses---containing names, locations, ratings, categories, and
review counts---and another on user-generated reviews with review texts,
dates, ratings, and user/business identifiers.

The steps involved cleaning and merging these datasets. Duplicate
entries were removed from all three sources to avoid inflating the final
cleaned datasets. For attractions, duplicates were identified by name;
for businesses, by name, address, neighborhood, and postal code (to
account for chains); and for reviews, by comparing user IDs, business
IDs, review texts, and ratings. The Yelp Business dataset had the most
duplicate entries---356 rows---likely due to updates in business
information. We retained the most recent entries by selecting rows with
the highest review count or open status. After filtering only Toronto
businesses and removing entries with missing coordinates, we merged them
with the attractions dataset by identifying the nearest attraction to
each business using a KDTree spatial index. Each business was then
linked to its closest attraction along with the distance between them.
Lastly, we merged the cleaned Yelp reviews with this Toronto business
data to enrich the context for each review.

Data wrangling and exploratory analysis were primarily conducted using
Pandas. The merged business-attractions dataset contained 17,199
businesses and 17 variables, while the reviews dataset included 430,906
cleaned reviews with 11 variables. We validated geographic coordinates
to ensure all businesses were within Toronto's bounds (latitude:
43.5--43.9, longitude: --79.6 to --79.2) and corrected minor
inconsistencies such as erroneous state codes (e.g., changing `AB' to
`ON' for businesses clearly located in Toronto). Additional review text
cleaning was also done to eliminate redundant or copied content. While
exact duplicate reviews were not found, some review texts appeared
multiple times across different users or businesses. To address this, we
retained only the earliest version of each duplicate text and removed
instances where a review was shared under multiple user IDs---unless the
businesses being reviewed were different.

All of these results in the final two datasets; \textbf{cleaned business
dataset and reviews dataset.} This extensive preprocessing ensured that
the final datasets accurately represented Toronto businesses, their
closest attractions, and authentic customer feedback. An initial
exploratory data analysis was also conducted, as well as
\textbf{sentiment analysis} using VADER that computes a compound\_score,
a single numerical value summarizing the overall sentiment of the review
on a scale from --1 (extremely negative) to +1 (extremely positive). We
also assigned each review a categorical sentiment label---positive,
neutral, or negative---based on this score. Thus, in addition to the
cleaned business dataset and reviews dataset, we also created a
\textbf{merged dataset that contained the sentiment analysis result}.
These final datasets are the one that we are using here, setting the
foundation for the analysis and modeling to follow.

\subsection{B.2. Exploratory Data Analysis (Extended
EDA)}\label{b.2.-exploratory-data-analysis-extended-eda}

The extended exploratory data analysis employed a comprehensive suite of
visualization techniques to uncover patterns and relationships within
the Toronto business ecosystem. The analysis was conducted using R's
tidyverse packages along with specialized visualization libraries to
create interactive and informative data explorations.

For geospatial analysis, we developed an interactive Leaflet map that
visualized all Toronto businesses color-coded by their average ratings.
The map used a red-yellow-green (RdYlGn) color gradient to represent
ratings from 1 to 5 stars, with pop-up markers that displayed detailed
business information including name, category, rating, and nearest
attraction details. This spatial visualization allowed us to examine
potential geographic clustering of high and low-rated businesses in
relation to tourist attractions.

To understand how proximity to attractions might influence business
visibility, we created comparative boxplots using Plotly. These
interactive visualizations compared review counts between businesses
located within 1 kilometer of an attraction versus those in regular
neighborhoods. The plots incorporated jittered points to show individual
business distributions while maintaining traditional boxplot statistics,
with hover functionality that revealed specific business names and exact
review counts. This approach provided insights into how tourist foot
traffic might affect online engagement.

Sentiment analysis formed a crucial component of our EDA. We implemented
a three-way sentiment classification system (positive/neutral/negative)
based on VADER compound scores and visualized the distribution across
all reviews using interactive bar charts. These charts included both raw
counts and percentage calculations, with hover-text functionality that
allowed users to explore the precise breakdown of sentiment across the
dataset. The visualizations revealed the overwhelming predominance of
positive sentiment in Toronto business reviews.

For textual analysis, we developed positive-sentiment (since it is the
dominant on reviews sentiment for Toronto businesses) word clouds using
the tidytext package for tokenization and processing. The analysis
incorporated custom stopword removal to filter out common but
uninformative terms, including location-specific words like ``Toronto.''
The word clouds were limited to the top 50 most frequent terms to
maintain clarity and interpretability. This approach helped identify key
themes and descriptors for positive-labeled reviews.

The technical implementation leveraged several specialized R packages:
leaflet for geospatial visualization, plotly for interactive charts,
wordcloud2 for textual analysis, and tidytext for natural language
processing tasks. All visualizations were designed with interactive
elements to enable deeper exploration of the underlying data patterns
while maintaining clean default views. For spatial calculations, we used
the WGS84 coordinate reference system (latitude/longitude) to ensure
accuracy in our location-based analyses. This multifaceted EDA approach
provided both macro-level pattern identification through aggregate
visualizations and micro-level investigation capabilities via
interactive tooltips across all key dataset dimensions.

\subsection{B.3. Predictive Modelling}\label{b.3.-predictive-modelling}

The predictive modeling approach employed two distinct classification
frameworks to analyze Yelp business ratings. First, a multi-class
classification system categorized ratings into three groups: low
(\textless3), medium (=3), and high (\textgreater3). Second, a binary
classification system simplified this into low (\textless3) and high
(≥3) categories by excluding the ambiguous medium ratings. This dual
approach allowed for comparison of model performance across different
classification complexities.

Two advanced machine learning algorithms were implemented for each
classification task:

\subsubsection{XGBoost}\label{xgboost}

The XGBoost algorithm was selected for its superior performance in
handling structured data and its ability to capture complex feature
interactions through gradient-boosted decision trees. This approach was
particularly suitable for our dataset, as it efficiently manages mixed
data types (numerical and categorical) while minimizing overfitting
through regularization. We implemented XGBoost with 150 boosting rounds
(nrounds), a maximum tree depth of 6, and a conservative learning rate
(eta = 0.1) to ensure stable convergence. Feature subsampling (80\%) and
column subsampling by tree (80\%) were applied to enhance model
robustness. The algorithm's native support for multi-class
classification (``multi:softmax'' objective) made it ideal for comparing
both our 3-class and binary rating predictions. XGBoost's built-in
feature importance metrics also allowed us to identify key
predictors---particularly useful given our hypothesis about sentiment
and location features driving rating patterns.

\subsubsection{Random Forest}\label{random-forest}

Random Forest was chosen as a comparative benchmark due to its inherent
resistance to overfitting and ability to handle non-linear relationships
without extensive hyperparameter tuning. By constructing 200 decision
trees on random subsets of data and features, the model naturally
accounts for variability in our dataset while maintaining
interpretability. Unlike XGBoost's sequential error correction, Random
Forest's parallelized bagging approach provided a different perspective
on feature importance, helping validate the consistency of key
predictors like compound\_score and nearest\_attraction\_category. We
maintained default parameters (mtry = sqrt(p) for classification) to
leverage the algorithm's ``out-of-the-box'' reliability, though this
came at the cost of XGBoost's fine-grained optimization capabilities.
The implementation served as a robust baseline to confirm whether
performance gains from XGBoost justified its additional complexity,
especially for our binary classification task where both algorithms
achieved similar accuracy.

The technical implementation utilized R's caret package for streamlined
model training and evaluation. The dataset was split into 80\% training
and 20\% testing sets using stratified sampling (random seed = 42) to
maintain class distribution. Categorical features underwent one-hot
encoding via dummyVars() to ensure proper numerical representation. Key
predictive features included sentiment analysis outputs (both
categorical labels and continuous compound scores), user engagement
metrics (useful, funny, cool votes) and business location context
(nearest attraction category).

Model performance was evaluated using classification accuracy and
confusion matrices, with particular attention to the training-test
accuracy gap as an indicator of overfitting. Feature importance analysis
was conducted for XGBoost models using gain metrics, revealing the
relative contribution of each predictor. The implementation leveraged
xgboost and randomForest packages, with supplementary visualization
through ggplot2 for result interpretation.

This methodological framework enabled systematic comparison of how
different feature combinations and algorithm choices affected predictive
performance across both classification paradigms, while maintaining
reproducibility through fixed random seeds and version-controlled data
processing pipelines.

\section{C. Results}\label{c.-results}

\subsection{C.1. Observation from Extended Exploratory Data
Analysis}\label{c.1.-observation-from-extended-exploratory-data-analysis}

\subsection{C.2. Machine Learning}\label{c.2.-machine-learning}

\section{D. Conclusion and Summary}\label{d.-conclusion-and-summary}

jangan lupa limitation

\end{document}
